# üîß Configura√ß√£o do Token do Hugging Face

## Problema Identificado

O modelo **Llama 3.1 8B-Instruct** √© um reposit√≥rio "gated" (protegido) no Hugging Face, o que significa que requer:
1. Aceitar os termos de uso
2. Autentica√ß√£o com token

## Erro Encontrado

```
401 Client Error: Unauthorized
Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted.
```

## ‚úÖ Solu√ß√£o

### Passo 1: Obter Acesso ao Modelo

1. Acesse: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct
2. Fa√ßa login (ou crie uma conta gratuita)
3. **Aceite os termos de uso** do modelo
4. Aguarde aprova√ß√£o (geralmente instant√¢nea)

### Passo 2: Criar Token de Acesso

1. Acesse: https://huggingface.co/settings/tokens
2. Clique em "New token"
3. Escolha um nome (ex: "IADvogado")
4. Selecione o tipo "Read" (leitura √© suficiente)
5. Clique em "Generate token"
6. **Copie o token** (voc√™ s√≥ ver√° ele uma vez!)

### Passo 3: Configurar o Token

#### Op√ß√£o A: Vari√°vel de Ambiente (Recomendado para desenvolvimento)

**Windows PowerShell:**
```powershell
$env:HUGGING_FACE_HUB_TOKEN="seu_token_aqui"
```

**Windows CMD:**
```cmd
set HUGGING_FACE_HUB_TOKEN=seu_token_aqui
```

**Linux/Mac:**
```bash
export HUGGING_FACE_HUB_TOKEN="seu_token_aqui"
```

#### Op√ß√£o B: Arquivo .env (Recomendado para produ√ß√£o)

1. Crie um arquivo `.env` na **raiz do projeto** (`IADvogado/`)
2. Adicione:
```env
HUGGING_FACE_HUB_TOKEN=seu_token_aqui
```

3. O arquivo `.env` j√° est√° configurado para ser lido automaticamente

### Passo 4: Verificar Configura√ß√£o

Ap√≥s configurar, reinicie o servidor:
```bash
python run_server.py
```

O modelo ser√° carregado automaticamente quando necess√°rio (lazy loading).

## üîç Verifica√ß√£o

Para verificar se est√° funcionando:

1. Inicie o servidor (deve iniciar sem erros agora)
2. Fa√ßa uma requisi√ß√£o de upload de documento
3. Verifique os logs - deve aparecer "Carregando modelo..." na primeira requisi√ß√£o

## ‚ö†Ô∏è Notas Importantes

- O token √© **confidencial** - n√£o compartilhe publicamente
- Adicione `.env` ao `.gitignore` se usar Git
- O modelo s√≥ ser√° carregado quando necess√°rio (primeira requisi√ß√£o)
- Se o token n√£o estiver configurado, o sistema usar√° fallback (respostas gen√©ricas)

## üÜò Fallback

Se o modelo n√£o puder ser carregado (token inv√°lido, sem acesso, etc.), o sistema:
- ‚úÖ Continuar√° funcionando
- ‚úÖ Usar√° respostas de fallback gen√©ricas
- ‚úÖ N√£o quebrar√° o servidor

## üìù Alternativas (Sem Token)

Se voc√™ n√£o quiser configurar o token agora, o sistema funcionar√° com respostas de fallback. Para testar o chatbot sem o modelo:

1. Execute o servidor normalmente
2. Fa√ßa upload de documentos
3. Receber√° respostas gen√©ricas mas estruturadas

Para usar IA real, configure o token conforme acima.

